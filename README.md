# ToxicCommentGuard: Advanced Toxic Comment Detection & Insights Platform
## Objectives:
- Toxic Comment Detection: Automatically classify whether a comment is toxic or non-toxic using supervised machine learning models.
- Sentiment Analysis: Analyze the emotional tone behind the comments and correlate with toxicity levels.
- Comment Categorization: Identify sub-types of toxicity such as insult, obscene, identity hate, threat, etc.
- Interactive Insights Dashboard: Build an intuitive dashboard to visualize model performance, sentiment distribution, and comment trends.

## Project Description:
    ToxicCommentGuard is a machine learning-powered web application designed to detect and analyze toxic language in user-generated comments. The project aims to create a safer and more respectful digital environment by identifying offensive content and providing insights into toxic behavior patterns. Built using Python and Streamlit, the platform leverages Natural Language Processing (NLP) techniques to classify comments, perform sentiment analysis, and generate interactive dashboards for better understanding of toxicity trends.The platform supports multilingual inputs and can classify toxic content written in various languages using models like mBERT and XLM-RoBERTa, ensuring broader inclusivity and accuracy in global moderation.

